{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1. What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "\n",
        "**Answer**-Simple Linear Regression (SLR) is a statistical method used to model the relationship between two quantitative variables:\n",
        "\n",
        " * One independent (predictor) variable ‚Äî usually denoted as\n",
        "\n",
        " * One dependent (response) variable ‚Äî usually denoted as\n",
        "\n",
        " ùëå Y\n",
        "\n",
        " Purpose of Simple Linear Regression\n",
        "\n",
        "1. Prediction:\n",
        "Estimate or predict the value of ùëå Y for a given ùëã X. Example: Predicting a person‚Äôs weight based on their height.\n",
        "\n",
        "Explanation: Understand the strength and direction of the relationship between ùëã X and ùëå Y. Example: Determining whether higher study time leads to better exam scores.\n",
        "\n",
        "Quantifying Relationships: The slope ( ùõΩ 1 Œ≤ 1‚Äã\n",
        "\n",
        ") quantifies how much ùëå Y is expected to change for a one-unit increase in ùëã X.\n",
        "\n"
      ],
      "metadata": {
        "id": "HjPTsbd1STD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "\n",
        "**Answer**-\n",
        "\n",
        " 1. **Linearity**:\n",
        "\n",
        "There must be a linear relationship between the independent variable (X) and the dependent variable (Y).\n",
        "\n",
        "This means: as X increases, Y changes at a constant rate.\n",
        "\n",
        "\n",
        "2. **Independence of Errors:**\n",
        "\n",
        "The residuals (errors) ‚Äî the differences between actual and predicted values ‚Äî should be independent of each other.\n",
        "\n",
        "In other words, one error should not depend on another.\n",
        "\n",
        " 3. Homoscedasticity (Equal Variance)\n",
        "\n",
        "The variance of the errors should remain constant across all values of X.\n",
        "\n",
        "That means the spread of residuals should be similar everywhere.\n",
        "\n",
        "üîπ 4. Normality of Errors\n",
        "\n",
        "The errors (residuals) should follow a normal distribution (bell-shaped curve).\n",
        "\n",
        "This is important for hypothesis testing and confidence intervals.\n",
        "\n",
        " Check: A histogram or Q-Q plot of residuals should look approximately normal.\n",
        "\n",
        " üîπ 5. No Multicollinearity\n",
        "\n",
        "This applies more to multiple regression, but in SLR it means:\n",
        "\n",
        "The independent variable (X) should not be a linear combination of other variables.\n",
        "\n",
        "(Since SLR has only one X, this assumption is automatically satisfied.)\n",
        "\n",
        "üîπ 6. No Significant Outliers\n",
        "\n",
        "Extreme outliers can distort the regression line and affect the slope and intercept.\n",
        "\n",
        "Outliers should be checked and treated if necessary.\n",
        "\n",
        "**Summary Table**\n",
        "\n",
        "| **Assumption**   | **Meaning**                            | **Effect if Violated**         |\n",
        "| ---------------- | -------------------------------------- | ------------------------------ |\n",
        "| Linearity        | Relationship between X and Y is linear | Predictions become inaccurate  |\n",
        "| Independence     | Errors are independent                 | Model becomes biased           |\n",
        "| Homoscedasticity | Constant error variance                | Estimates become inefficient   |\n",
        "| Normality        | Errors are normally distributed        | Invalid hypothesis tests       |\n",
        "| No Outliers      | No extreme abnormal data points        | Model parameters get distorted |\n"
      ],
      "metadata": {
        "id": "S9IsPXrUWKWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Write the mathematical equation for a simple linear regression model and\n",
        "explain each term.\n",
        "\n",
        "**Answer**-Simple Linear Regression Equation\n",
        "\n",
        "ùëå=\n",
        "ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ\n",
        "1\n",
        "x\n",
        "+\n",
        "ùúÄ\n",
        "\n",
        "Explanation of Each Term\n",
        "\n",
        ". Y ‚Üí Dependent variable (the output or target value we want to predict)\n",
        "\n",
        ". X ‚Üí Independent variable (the input or predictor variable used for prediction)\n",
        "\n",
        ". Œ≤‚ÇÄ (Beta Zero) ‚Üí Intercept term ‚Äî the value of Y when X=0\n",
        "\n",
        "\n",
        ". Œ≤‚ÇÅ (Beta One) ‚Üí Slope coefficient ‚Äî it represents how much\n",
        "ùëå\n",
        "Y changes for a one-unit change in\n",
        "ùëã\n",
        "X\n",
        "\n",
        ". Œµ (Epsilon) ‚Üí Error term ‚Äî the difference between the actual value and the predicted value; it accounts for randomness or factors not included in the model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PBGRwh8UWmY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Provide a real-world example where simple linear regression can be\n",
        "applied.\n",
        "\n",
        "**Answer**-Real-World Example of Simple Linear Regression\n",
        "\n",
        "A real-world example of simple linear regression is predicting the price of a house based on its size.\n",
        "\n",
        "Price=Œ≤0\n",
        "\t+Œ≤1\n",
        "\t‚Äã\n",
        "√óSize+Œµ\n",
        "\n",
        "Explanation:\n",
        "In this example,\n",
        "\n",
        ". Dependent variable (Y): House Price (the value to be predicted)\n",
        "\n",
        ". Independent variable (X): Size of the house (in square feet or square meters)\n",
        "\n",
        ". Œ≤‚ÇÄ: Intercept ‚Äî the estimated base price when the house size is zero\n",
        "\n",
        ". Œ≤‚ÇÅ: Slope ‚Äî shows how much the price increases for each additional unit of size\n",
        "\n",
        ". Œµ: Error term ‚Äî represents other factors like location, age, or condition of the house\n",
        "\n",
        "| **Term** | **Meaning**          | **Description**                                                         |\n",
        "| -------- | -------------------- | ----------------------------------------------------------------------- |\n",
        "| **Y**    | Dependent Variable   | House Price (the value we want to predict)                              |\n",
        "| **X**    | Independent Variable | Size of the house (in square feet or square meters)                     |\n",
        "| **Œ≤‚ÇÄ**   | Intercept            | The estimated base price when the house size is zero                    |\n",
        "| **Œ≤‚ÇÅ**   | Slope Coefficient    | Change in house price for each additional unit of size                  |\n",
        "| **Œµ**    | Error Term           | Represents other factors like location, age, and condition of the house |\n"
      ],
      "metadata": {
        "id": "l9D3_TWBWVVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What is the method of least squares in linear regression?\n",
        "\n",
        "**Answer**-\n",
        "\n",
        "Method of Least Squares in Linear Regression\n",
        "\n",
        "The method of least squares is a mathematical approach used in linear regression to find the best-fitting line through a set of data points by minimizing the sum of the squared errors (differences) between the actual and predicted values.\n",
        "\n",
        "**Mathematical Explanation**\n",
        "\n",
        "If the regression line is:\n",
        "\n",
        "Y=Œ≤0‚Äã+Œ≤1‚ÄãX\n",
        "\n",
        "\n",
        "Then, for each data point\n",
        "(\n",
        "ùëã\n",
        "ùëñ\n",
        ",\n",
        "ùëå\n",
        "ùëñ\n",
        " ) the predicted value is:\n",
        "\n",
        " Yi‚Äã^‚Äã=Œ≤0‚Äã+Œ≤1‚ÄãXi‚Äã\n",
        "\n",
        "\n",
        "The error (residual) for each point is:\n",
        "\n",
        "\n",
        "ei‚Äã=Yi‚Äã‚àíYi‚Äã^‚Äã\n",
        "\n",
        "The least squares method minimizes the sum of squared errors (SSE):\n",
        "\n",
        "SSE=‚àë(Yi‚Äã‚àíYi‚Äã^‚Äã)2\n",
        "\n",
        "The values of\n",
        "ùõΩ\n",
        "0\n",
        "and\n",
        "ùõΩ\n",
        "1\n",
        "are chosen so that this SSE is as small as possible.\n",
        "\n",
        "**In Simple Words:**\n",
        "\n",
        "It finds the line that makes the predicted values (≈∂) as close as possible to the actual values (Y) by reducing the total squared distance between them.\n",
        "\n",
        "Example:\n",
        "\n",
        "In predicting house prices based on size, the least squares method adjusts the line so that the difference between actual prices and predicted prices is minimized across all houses.\n",
        "\n",
        "\n",
        "| **Term**                        | **Meaning**     | **Description**                                                             |\n",
        "| ------------------------------- | --------------- | --------------------------------------------------------------------------- |\n",
        "| **Y**                           | Actual Value    | The observed value from the dataset                                         |\n",
        "| **≈∂ (Y-hat)**                   | Predicted Value | The value predicted by the regression line                                  |\n",
        "| **Œ≤‚ÇÄ**                          | Intercept       | The value of Y when X = 0                                                   |\n",
        "| **Œ≤‚ÇÅ**                          | Slope           | The change in Y for a one-unit change in X                                  |\n",
        "| **Œµ (Error Term)**              | Residual        | The difference between actual and predicted values (Y - ≈∂)                  |\n",
        "| **SSE (Sum of Squared Errors)** | Error Measure   | The total of squared residuals, which we minimize to find the best-fit line |\n"
      ],
      "metadata": {
        "id": "ASLw9LSt2kCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        "\n",
        "**Answer**-\n",
        "\n",
        "1. **Introduction to Logistic Regression**\n",
        "\n",
        "Logistic Regression is a supervised machine learning algorithm that is mainly used for classification problems. It helps to predict the probability of an outcome that can only have two possible values, such as Yes/No, 0/1, True/False, or Pass/Fail.\n",
        "Although it has the word ‚ÄúRegression‚Äù in its name, it is actually used for classification tasks, not for predicting continuous numeric values.\n",
        "\n",
        "The main idea behind Logistic Regression is to find a relationship between one or more independent variables (predictors) and a categorical dependent variable by using a logistic (sigmoid) function.\n",
        "\n",
        "2. **Mathematical Representation**\n",
        "\n",
        "The logistic regression model predicts the probability that an instance belongs to a certain class. The mathematical equation is:\n",
        "\n",
        "P(Y=1‚à£X)= 1+e‚àí(b0‚Äã+b1‚ÄãX)1‚Äã\n",
        "\n",
        "Where:\n",
        "\n",
        ".\n",
        "ùëÉ\n",
        "(\n",
        "ùëå=\n",
        "1\n",
        "‚à£\n",
        "ùëã\n",
        ")\n",
        "P(Y=1‚à£X): Probability that the output belongs to class 1 (for example, ‚ÄúYes‚Äù or ‚ÄúPass‚Äù)\n",
        "\n",
        "\n",
        ". e: Base of the natural logarithm (‚âà 2.718)\n",
        "\n",
        ". ùëè\n",
        "0\n",
        ": Intercept term\n",
        "\n",
        "ùëè\n",
        "1\n",
        ": Coefficient or slope of the independent variable\n",
        "ùëã\n",
        "\n",
        "\n",
        "This equation transforms a linear combination of input variables into a value between 0 and 1, which represents a probability.\n",
        "If the predicted probability is greater than 0.5, the output is classified as ‚Äú1‚Äù; otherwise, it is classified as ‚Äú0‚Äù.\n",
        "\n",
        "\n",
        "3. **The Sigmoid Function**\n",
        "\n",
        "The sigmoid function (also known as the logistic function) is the core of logistic regression.\n",
        "\n",
        "It is given by:\n",
        "\n",
        "f(x)=1+e‚àíx1‚Äã\n",
        "\n",
        "This function converts any real number into a range between 0 and 1.\n",
        "The graph of the sigmoid function has an S-shaped curve, which makes it ideal for mapping predicted values to probabilities.\n",
        "\n",
        "4. **Example**\n",
        "\n",
        "Let‚Äôs take an example of predicting whether a student will pass or fail an exam based on their study hours.\n",
        "\n",
        "| Study Hours (X) | Pass (Y) |\n",
        "| --------------- | -------- |\n",
        "| 1               | 0        |\n",
        "| 2               | 0        |\n",
        "| 3               | 0        |\n",
        "| 4               | 1        |\n",
        "| 5               | 1        |\n",
        "| 6               | 1        |\n",
        "\n",
        "Here, the dependent variable ‚ÄúPass‚Äù can only take two values: 0 (Fail) or 1 (Pass).\n",
        "Logistic Regression will fit a sigmoid curve to this data and predict the probability that a student will pass depending on the number of hours they study.\n",
        "For example, it might predict that a student who studies 3.5 hours has a 65% chance of passing (i.e., P = 0.65).\n",
        "\n",
        "\n",
        "5. **Method of Estimation**\n",
        "\n",
        "Logistic Regression uses a method called Maximum Likelihood Estimation (MLE) instead of the Least Squares method (used in Linear Regression).\n",
        "The goal of MLE is to find the values of parameters\n",
        "ùëè\n",
        "0\n",
        "b\n",
        "0\n",
        "\t‚Äã\n",
        "and\n",
        "ùëè\n",
        "1\n",
        "b\n",
        "1\n",
        "\t‚Äã that make the observed data most probable.\n",
        "\n",
        "In simple words, it finds the best-fitting model that maximizes the probability of the given data.\n",
        "\n",
        "6. **Difference between Logistic Regression and Linear Regression**\n",
        "\n",
        "| **Basis**              | **Linear Regression**                                                          | **Logistic Regression**                                                               |\n",
        "| ---------------------- | ------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------- |\n",
        "| **Purpose**            | Used to predict **continuous numeric values** such as salary, marks, or price. | Used to predict **categorical outcomes** such as Yes/No, Pass/Fail, or Spam/Not Spam. |\n",
        "| **Type of Problem**    | Regression problem                                                             | Classification problem                                                                |\n",
        "| **Dependent Variable** | Continuous (e.g., real numbers)                                                | Categorical (e.g., 0 or 1)                                                            |\n",
        "| **Equation**           | ( Y = b_0 + b_1X )                                                             | ( P(Y=1) = \\frac{1}{1 + e^{-(b_0 + b_1X)}} )                                          |\n",
        "| **Output Range**       | Can take any real value (‚àí‚àû to +‚àû)                                             | Always between 0 and 1 (represents probability)                                       |\n",
        "| **Relationship Type**  | Assumes a **linear relationship** between variables                            | Uses **logistic/sigmoid transformation** to make predictions                          |\n",
        "| **Graph**              | Straight line                                                                  | S-shaped curve (sigmoid curve)                                                        |\n",
        "| **Error Measurement**  | Measured using **Mean Squared Error (MSE)**                                    | Measured using **Log Loss** or **Cross-Entropy Loss**                                 |\n",
        "| **Estimation Method**  | Ordinary Least Squares (OLS)                                                   | Maximum Likelihood Estimation (MLE)                                                   |\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lkKdLPqf4nI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Name and briefly describe three common evaluation metrics for regression\n",
        "models.\n",
        "\n",
        "**Answer**-\n",
        "\n",
        "1. **Mean Absolute Error (MAE)**\n",
        "\n",
        "Definition:\n",
        "\n",
        "MAE measures the average magnitude of errors in a set of predictions, without considering their direction.\n",
        "It‚Äôs the mean of the absolute differences between actual and predicted values.\n",
        "\n",
        "Formula:\n",
        "\n",
        "MAE=n1‚Äãi=1‚àën‚Äã‚à£yi‚Äã‚àíy^‚Äãi‚Äã‚à£\n",
        "\n",
        "Explanation:\n",
        "\n",
        ". It shows how far the predictions are, on average, from the true values.\n",
        "\n",
        ". Lower MAE means better model accuracy.\n",
        "\n",
        "2. **Mean Squared Error (MSE)**\n",
        "\n",
        "Definition:\n",
        "\n",
        "MSE calculates the average of the squared differences between predicted and actual values.\n",
        "\n",
        "Formula:\n",
        "\n",
        "MSE=n1‚Äãi=1‚àën‚Äã(yi‚Äã‚àíy^‚Äãi‚Äã)2\n",
        "\n",
        "Explanation:\n",
        "\n",
        ". It penalizes larger errors more heavily because of squaring.\n",
        "\n",
        ". Useful when you want to emphasize large deviations.\n",
        "\n",
        "3. **R-squared (Coefficient of Determination)**\n",
        "\n",
        "Definition:\n",
        "\n",
        "R¬≤ measures how well the regression model explains the variability of the target variable.\n",
        "\n",
        "Formula:\n",
        "\n",
        "R\n",
        "2\n",
        "=1‚àí\n",
        "SS res/SS\n",
        "tot\n",
        "\t‚Äã\n",
        "\n",
        "where\n",
        "\n",
        "SS\n",
        "res\n",
        "\t‚Äã\n",
        "=‚àë(yi‚àí\n",
        "y^\n",
        "\t‚Äã\n",
        "i\n",
        "\t‚Äã\n",
        ")\n",
        "2\n",
        " and\n",
        "ùëÜ\n",
        "ùëÜ\n",
        "ùë°\n",
        "ùëú\n",
        "ùë°\n",
        "=\n",
        "‚àë\n",
        "(\n",
        "ùë¶\n",
        "ùëñ\n",
        "‚àí\n",
        "ùë¶\n",
        "Àâ\n",
        ")\n",
        "2\n",
        "SS\n",
        "tot\n",
        "\t‚Äã\n",
        "=‚àë(y\n",
        "i\n",
        "\t‚Äã‚àí\n",
        "y\n",
        "Àâ\n",
        "\t‚Äã\n",
        ")\n",
        "2\n",
        "\n",
        "Explanation:\n",
        "\n",
        ". R¬≤ ranges from 0 to 1.\n",
        "\n",
        ". A higher R¬≤ value means the model explains more variance in the data.\n",
        "\n",
        "| Metric | Full Form                    | Measures                                                        | Ideal Value | Key Point              |\n",
        "| :----- | :--------------------------- | :-------------------------------------------------------------- | :---------- | :--------------------- |\n",
        "| MAE    | Mean Absolute Error          | Average absolute difference between actual and predicted values | Closer to 0 | Easy to interpret      |\n",
        "| MSE    | Mean Squared Error           | Average of squared errors                                       | Closer to 0 | Penalizes large errors |\n",
        "| R¬≤     | Coefficient of Determination | Proportion of variance explained by model                       | Closer to 1 | Explains model fit     |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vmGu2ipuvpeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "**Answer-**  \n",
        "\n",
        "Purpose of the R-squared Metric in Regression Analysis\n",
        "\n",
        "The R-squared (R¬≤) metric, also known as the coefficient of determination, is an important measure used in regression analysis to evaluate how well the independent variables explain the variation in the dependent variable. In simple terms, it tells us how closely the data fit the regression line or how well the model represents the real-world data.\n",
        "\n",
        "The value of R-squared ranges between 0 and 1. An R¬≤ value of 0 indicates that the model does not explain any of the variability in the dependent variable, while an R¬≤ value of 1 means the model explains all of the variability perfectly. Generally, a higher R¬≤ value means a better fit of the model to the data, but it does not always guarantee that the model is good‚Äîsometimes, a very high R¬≤ can indicate overfitting if unnecessary variables are included.\n",
        "\n",
        "Mathematically, R-squared is calculated using the formula:\n",
        "\n",
        "R2=1‚àí‚ÄãSSres/SStot‚Äã‚Äã\n",
        "\n",
        "Where:\n",
        "\n",
        ". SS\n",
        "res:\n",
        "\t‚Äã\n",
        "\n",
        " is the sum of squared residuals (errors) ‚Äî the difference between the actual and predicted value\n",
        "\n",
        ". SS\n",
        "tot:\n",
        "\t‚Äã\n",
        "\n",
        " is the total sum of squares, representing the total variation in the actual data.\n",
        "\n",
        " For example, if we build a regression model to predict house prices based on the size of the house, and we get an R¬≤ value of 0.85, it means that 85% of the variation in house prices can be explained by the model, while the remaining 15% is due to other factors not included in the model.\n",
        "\n",
        " In conclusion, the purpose of the R-squared metric is to measure the goodness of fit of a regression model. It helps us understand how well the model‚Äôs predictions match the observed data, and it serves as an important tool for evaluating and comparing different regression models.\n"
      ],
      "metadata": {
        "id": "6EtSwxFAafYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept.\n",
        "\n"
      ],
      "metadata": {
        "id": "RPeqja_QcsRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**"
      ],
      "metadata": {
        "id": "CVrJWKDyc0F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "y = np.array([6, 7, 8, 9, 5])\n",
        "\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "\n",
        "print(\"Slope (Coefficient):\", model.coef_[0])\n",
        "print(\"Intercept:\", model.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7MZ1WhCc13j",
        "outputId": "d9b33c1c-0a84-4f19-9fa1-4efa4b7ae2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Coefficient): 7.021666937153402e-17\n",
            "Intercept: 7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: How do you interpret the coefficients in a simple linear regression model?\n",
        "\n",
        "**Answer**-\n",
        "\n",
        "Interpretation of Coefficients in a Simple Linear Regression Model\n",
        "\n",
        "In a simple linear regression model, the relationship between one independent variable (X) and one dependent variable (Y) is expressed by the equation:\n",
        "\n",
        "Y=Œ≤0‚Äã+Œ≤1‚ÄãX+Œµ\n",
        "\n",
        "Where:\n",
        "\n",
        "\n",
        ". Y = Dependent variable (the value we want to predict)\n",
        "\n",
        "\n",
        ". X = Independent variable (the predictor)\n",
        "\n",
        "\n",
        ". Œ≤\n",
        "0\n",
        "\t‚Äã\n",
        " = Intercept (constant term)\n",
        "\n",
        "\n",
        ". Œ≤\n",
        "1\n",
        "\t‚Äã\n",
        " = Coefficient or slope of the independent variable\n",
        "\n",
        "\n",
        ". Œµ = Error term (difference between actual and predicted values)\n",
        "\n",
        "1. Intercept (Œ≤‚ÇÄ):\n",
        "\n",
        "The intercept represents the predicted value of Y when X = 0.\n",
        "\n",
        "It shows where the regression line crosses the Y-axis.\n",
        "\n",
        ". For example, if the regression equation is\n",
        "\n",
        "Y=5+2X\n",
        "\n",
        "then\n",
        "\n",
        "Œ≤\n",
        "0\n",
        "\t‚Äã\n",
        "=5.\n",
        "\n",
        "This means that when\n",
        "X=0, the predicted value of\n",
        "Y is 5.\n",
        "\n",
        "However, in some cases, the intercept might not have a meaningful real-world interpretation (especially when X = 0 is not realistic, like ‚Äú0 years of age‚Äù for adults).\n",
        "\n",
        "2. Slope (Œ≤‚ÇÅ):\n",
        "\n",
        "The slope coefficient (Œ≤‚ÇÅ) represents the change in the dependent variable (Y) for a one-unit increase in the independent variable (X), keeping all other factors constant.\n",
        "\n",
        ". Continuing the same example:\n",
        "\n",
        "Y=5+2X\n",
        "\n",
        "Here,\n",
        "Œ≤\n",
        "1\n",
        "\t‚Äã\n",
        "=2.\n",
        "\n",
        "This means that for every one-unit increase in X, the predicted value of\n",
        "ùëå\n",
        "Y increases by 2 units.\n",
        "\n",
        "The sign of Œ≤‚ÇÅ also indicates the direction of the relationship:\n",
        "\n",
        ". Positive Œ≤‚ÇÅ: As X increases, Y increases (positive relationship).\n",
        "\n",
        ". Negative Œ≤‚ÇÅ: As X increases, Y decreases (negative relationship).\n",
        "\n",
        "Example:\n",
        "\n",
        ". Suppose you are predicting house prices (Y) based on size in square feet (X).\n",
        "If your model is:\n",
        "\n",
        "Price=50,000+\n",
        "\n",
        "Then:\n",
        "\n",
        ". Intercept (Œ≤‚ÇÄ = 50,000): When house size is 0 sq.ft, the base price is ‚Çπ50,000 (may not be practical but serves as a mathematical reference).\n",
        "\n",
        ". Slope (Œ≤‚ÇÅ = 200): For each additional 1 sq.ft, the price increases by ‚Çπ200.\n",
        "\n",
        "| Coefficient        | Meaning                                | Interpretation                                  |\n",
        "| ------------------ | -------------------------------------- | ----------------------------------------------- |\n",
        "| **Œ≤‚ÇÄ (Intercept)** | Predicted value of Y when X = 0        | Starting or baseline value of Y                 |\n",
        "| **Œ≤‚ÇÅ (Slope)**     | Change in Y for a one-unit change in X | Measures strength and direction of relationship |\n"
      ],
      "metadata": {
        "id": "Vvh84NLpd3Ym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "byMfG2Yyglbk"
      }
    }
  ]
}